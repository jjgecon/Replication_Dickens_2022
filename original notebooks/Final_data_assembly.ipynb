{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e95c3b9a-a9f4-4f70-8032-80064d5dcb32",
   "metadata": {},
   "source": [
    "This notebook gathers the data collected from our buffers and alternative buffers contructed in the notebooks `Construct-Buffers-v17`, `Construct-Buffers-v16`, `Construct-AltBuffers-v17.ipynb`, and `Construct-AltBuffers-v16` and combines it with Dicken's own dataset.\n",
    "\n",
    "Note that each of the above-mentioned notebooks require the Ethnologe to run which is protected under copy rights. Therefore, these notebooks can't be run here on Deepnote. However, you can see the outputs of each cell. If you want to understand how the data was constructed please review the notebooks.\n",
    "\n",
    "You need to change the variable `buffer_size_radius_km` equal to the radius of the buffer you want to create for notebooks `Construct-Buffers-v16` and `Construct-AltBuffers-v16`. To replicate the Dickens (2022) buffers you need to set up `buffer_size_radius_km=50` so that the buffers have a 100km diameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdae7b91-b400-402f-bdcd-5ac06844fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import sys, os, time\n",
    "pd.set_option('display.width', 140)\n",
    "\n",
    "from IPython.display import display, HTML, Image\n",
    "\n",
    "# pathdata = '/work/data/'\n",
    "\n",
    "# Do not use these lines in DEEPNOTE\n",
    "pathdata = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70780bb",
   "metadata": {},
   "source": [
    "Make sure to decompress the dataset `Dickens_AltBuf_v16_crops_absdif_50.zip` to get the dataset `Dickens_AltBuf_v16_crops_absdif_50.dta`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126aa9ea-d742-4359-91d5-f2cf0ac3505e",
   "metadata": {},
   "source": [
    "## Preparing the Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cf8dbe4-7d3c-4f50-a54b-f86b2dff9cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\48672590\\AppData\\Local\\Temp\\ipykernel_14104\\935551799.py:2: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  dfor = pd.read_stata(pathdata + 'EJ_Dickens_Border_100km.dta')\n"
     ]
    }
   ],
   "source": [
    "# Load all datasets\n",
    "dfor = pd.read_stata(pathdata + 'EJ_Dickens_Border_100km.dta')\n",
    "\n",
    "dfor_v16 = pd.read_stata(pathdata + 'Dickens_OrBuf_v16_stats_50.dta') # this naming convention is with the radius not the diameter\n",
    "dfor_v16_25 = pd.read_stata(pathdata + 'Dickens_OrBuf_v16_stats_25.dta')\n",
    "dfor_v16_100 = pd.read_stata(pathdata + 'Dickens_OrBuf_v16_stats_100.dta')\n",
    "\n",
    "dfor_v16_alt = pd.read_stata(pathdata + 'Dickens_AltBuf_v16_absdif_50.dta')\n",
    "dfor_v16_alt_25 = pd.read_stata(pathdata + 'Dickens_AltBuf_v16_absdif_25.dta')\n",
    "dfor_v16_alt_100 = pd.read_stata(pathdata + 'Dickens_AltBuf_v16_absdif_100.dta')\n",
    "\n",
    "# Load crop specific datasets\n",
    "dfor_crops = pd.read_stata(pathdata + 'Dickens_OrBuf_v16_cropstats_50.dta')\n",
    "dfor_crops_alt = pd.read_stata(pathdata + 'Dickens_AltBuf_v16_crops_absdif_50.dta')\n",
    "\n",
    "# Redefine some variables to be closer to what Dickens did with buffers defined by Dickens\n",
    "for df in [dfor_v16, dfor_v16_25, dfor_v16_100]:\n",
    "    df['csi_change_sd_oj'] = (df.post1500AverageCaloriesstd - df.pre1500AverageCaloriesstd)/1000\n",
    "    df['csi_sd_oj'] = (df.pre1500AverageCaloriesstd)/1000\n",
    "    df['csi_change_oj'] = (df.post1500AverageCaloriesmean - df.pre1500AverageCaloriesmean)/1000\n",
    "    df['csi_oj'] = (df.pre1500AverageCaloriesmean)/1000\n",
    "\n",
    "# Redefine some variables to be closer to what Dickens did with the alternative buffers\n",
    "for df in [dfor_v16_alt,dfor_v16_alt_25, dfor_v16_alt_100]:\n",
    "    df['csi_change_alt'] = (df.post1500AverageCaloriesmean - df.pre1500AverageCaloriesmean)/1000\n",
    "    df['csi_alt'] = (df.pre1500AverageCaloriesmean)/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd7d5ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the same for version v17 of the Ethnologe\n",
    "dfor_v17 = pd.read_stata(pathdata + 'Dickens_OrBuf_v17_stats.dta')\n",
    "dfor_v17_alt = pd.read_stata(pathdata + 'Dickens_AltBuf_v17_absdif.dta')\n",
    "\n",
    "dfor_v17['csi_change_sd_oj'] = (dfor_v17.post1500AverageCaloriesstd - dfor_v17.pre1500AverageCaloriesstd)/1000\n",
    "dfor_v17['csi_sd_oj'] = (dfor_v17.pre1500AverageCaloriesstd)/1000\n",
    "dfor_v17['csi_change_oj'] = (dfor_v17.post1500AverageCaloriesmean - dfor_v17.pre1500AverageCaloriesmean)/1000\n",
    "dfor_v17['csi_oj'] = (dfor_v17.pre1500AverageCaloriesmean)/1000\n",
    "\n",
    "# Redefine some variables to be closer to what Dickens did with the alternative buffers\n",
    "dfor_v17_alt['csi_change_alt'] = (dfor_v17_alt.post1500AverageCaloriesmean - dfor_v17_alt.pre1500AverageCaloriesmean)/1000\n",
    "dfor_v17_alt['csi_alt'] = (dfor_v17_alt.pre1500AverageCaloriesmean)/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b48f9fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine some variables to be easier to work with\n",
    "crop_vars = ['crop_' + col if col != 'identifier' else col for col in dfor_crops.columns]\n",
    "dfor_crops.columns = crop_vars\n",
    "crop_vars.remove('identifier')\n",
    "\n",
    "crop_alt_vars = ['crop_alt_' + col  if col not in ['identifier','ID_1','ID_2'] else col for col in dfor_crops_alt.columns]\n",
    "dfor_crops_alt.columns = crop_alt_vars\n",
    "crop_alt_vars.remove('identifier')\n",
    "crop_alt_vars.remove('ID_1')\n",
    "crop_alt_vars.remove('ID_2')\n",
    "\n",
    "# Now we need to normalize all the crop data\n",
    "for col in dfor_crops.columns:\n",
    "    if col == 'identifier':\n",
    "        continue\n",
    "    dfor_crops[col] = dfor_crops[col]/1000\n",
    "\n",
    "for col in dfor_crops_alt.columns:\n",
    "    if col in ['identifier','ID_1','ID_2']:\n",
    "        continue\n",
    "    dfor_crops_alt[col] = dfor_crops_alt[col]/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c44967e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To include some same language pairs \n",
    "dfor_v16_all = dfor_v16.merge(dfor, how = 'left', on = 'identifier')\n",
    "dfor_v16_all = dfor_v16_all.merge(dfor_v16_alt, how = 'left', on = 'identifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52769f02-1593-44be-99d3-7f3b1b965bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to make sure that we have the same as buffers zones Dicken, \n",
    "# so we will first restrict our sample to those that have information about lingDist\n",
    "dfor = dfor[dfor.lingDist.isna() == False]\n",
    "\n",
    "# Merge both the alternative measures and the original reconstruction\n",
    "dfor_v16 = dfor.merge(dfor_v16, how = 'left', on = 'identifier')\n",
    "dfor_v16 = dfor_v16.merge(dfor_v16_alt, how = 'left', on = 'identifier')\n",
    "dfor_v16 = dfor_v16.merge(dfor_crops, how = 'left', on = 'identifier')\n",
    "dfor_v16 = dfor_v16.merge(dfor_crops_alt, how = 'left', on = 'identifier')\n",
    "\n",
    "dfor_v16_25 = dfor.merge(dfor_v16_25, how = 'left', on = 'identifier')\n",
    "dfor_v16_25 = dfor_v16_25.merge(dfor_v16_alt_25, how = 'left', on = 'identifier')\n",
    "\n",
    "dfor_v16_100 = dfor.merge(dfor_v16_100, how = 'left', on = 'identifier')\n",
    "dfor_v16_100 = dfor_v16_100.merge(dfor_v16_alt_100, how = 'left', on = 'identifier')\n",
    "\n",
    "# Merge with ethnologe v17\n",
    "dfor_v17 = dfor.merge(dfor_v17, how = 'left', on = 'identifier')\n",
    "dfor_v17 = dfor_v17.merge(dfor_v17_alt, how = 'left', on = 'identifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56881474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to test if we consider those borders that share the same language like Mexico and Guatemala which both uses Spanish.\n",
    "same_language_pairs = pd.read_stata(pathdata + 'same_language_identifiers.dta')\n",
    "\n",
    "dfor_v16 = dfor_v16.merge(same_language_pairs, on='identifier', how='left')\n",
    "dfor_v16_25 = dfor_v16_25.merge(same_language_pairs, on='identifier', how='left')\n",
    "dfor_v16_100 = dfor_v16_100.merge(same_language_pairs, on='identifier', how='left')\n",
    "dfor_v16_all = dfor_v16_all.merge(same_language_pairs, on='identifier', how='left')\n",
    "dfor_v17 = dfor_v17.merge(same_language_pairs, on='identifier', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e04a12a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the dfor_v16_all and add the missing data of LingDist only to those that we identify as same language\n",
    "dfor_v16_all.loc[dfor_v16_all['same_lang'] == 1, 'lingDist'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae6d04d2-46f5-4159-8cbc-e0add2c5afee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8426\n",
      "8402\n",
      "8426\n",
      "8402\n",
      "8426\n",
      "8402\n",
      "(67025, 412)\n",
      "66964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\48672590\\AppData\\Local\\Temp\\ipykernel_14104\\2076897082.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  category_counts = dfor_v16_25.loc[dfor_v16_25.lingDist.isna()==False].groupby('family1').identifier.count()\n",
      "C:\\Users\\48672590\\AppData\\Local\\Temp\\ipykernel_14104\\2076897082.py:6: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  category_counts = dfor_v16_25.loc[dfor_v16_25.lingDist.isna()==False].groupby('family2').identifier.count()\n",
      "C:\\Users\\48672590\\AppData\\Local\\Temp\\ipykernel_14104\\2076897082.py:24: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  category_counts = dfor_v16_all.loc[dfor_v16_all.lingDist.isna()==False].groupby('family1').identifier.count()\n",
      "C:\\Users\\48672590\\AppData\\Local\\Temp\\ipykernel_14104\\2076897082.py:27: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  category_counts = dfor_v16_all.loc[dfor_v16_all.lingDist.isna()==False].groupby('family2').identifier.count()\n"
     ]
    }
   ],
   "source": [
    "# To get the same number of observations in the regressions we also need to identify family1 and family2 singletons\n",
    "# For 25km buffers\n",
    "category_counts = dfor_v16_25.loc[dfor_v16_25.lingDist.isna()==False].groupby('family1').identifier.count()\n",
    "singletop_fam1 = category_counts[category_counts == 1].index.tolist()\n",
    "\n",
    "category_counts = dfor_v16_25.loc[dfor_v16_25.lingDist.isna()==False].groupby('family2').identifier.count()\n",
    "singletop_fam2 = category_counts[category_counts == 1].index.tolist()\n",
    "\n",
    "dfor_v16_25['not_singletons'] = (~dfor_v16.family1.isin(singletop_fam1)) & (~dfor_v16_25.family2.isin(singletop_fam2))\n",
    "print(sum(dfor_v16_25.csi.isna() == False))\n",
    "print(sum(dfor_v16_25.not_singletons == 1))\n",
    "\n",
    "# For 50km buffers\n",
    "dfor_v16['not_singletons'] = (~dfor_v16.family1.isin(singletop_fam1)) & (~dfor_v16.family2.isin(singletop_fam2))\n",
    "print(sum(dfor_v16.csi_alt.isna() == False))\n",
    "print(sum(dfor_v16.not_singletons == 1))\n",
    "\n",
    "# For 100km buffers\n",
    "dfor_v16_100['not_singletons'] = (~dfor_v16_100.family1.isin(singletop_fam1)) & (~dfor_v16_100.family2.isin(singletop_fam2))\n",
    "print(sum(dfor_v16_100.csi_alt.isna() == False))\n",
    "print(sum(dfor_v16_100.not_singletons == 1))\n",
    "\n",
    "# For all borders\n",
    "category_counts = dfor_v16_all.loc[dfor_v16_all.lingDist.isna()==False].groupby('family1').identifier.count()\n",
    "singletop_fam1 = category_counts[category_counts == 1].index.tolist()\n",
    "\n",
    "category_counts = dfor_v16_all.loc[dfor_v16_all.lingDist.isna()==False].groupby('family2').identifier.count()\n",
    "singletop_fam2 = category_counts[category_counts == 1].index.tolist()\n",
    "dfor_v16_all['not_singletons'] = (~dfor_v16_all.family1.isin(singletop_fam1)) & (~dfor_v16_all.family2.isin(singletop_fam2))\n",
    "print(dfor_v16_all.shape)\n",
    "print(sum(dfor_v16_all.not_singletons == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f735cff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8431\n",
      "8407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\48672590\\AppData\\Local\\Temp\\ipykernel_14104\\2182301182.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  category_counts = dfor_v17.loc[dfor_v17.lingDist.isna()==False].groupby('family1').identifier.count()\n",
      "C:\\Users\\48672590\\AppData\\Local\\Temp\\ipykernel_14104\\2182301182.py:5: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  category_counts = dfor_v17.loc[dfor_v17.lingDist.isna()==False].groupby('family2').identifier.count()\n"
     ]
    }
   ],
   "source": [
    "# Do the same for v17\n",
    "category_counts = dfor_v17.loc[dfor_v17.lingDist.isna()==False].groupby('family1').identifier.count()\n",
    "singletop_fam1 = category_counts[category_counts == 1].index.tolist()\n",
    "\n",
    "category_counts = dfor_v17.loc[dfor_v17.lingDist.isna()==False].groupby('family2').identifier.count()\n",
    "singletop_fam2 = category_counts[category_counts == 1].index.tolist()\n",
    "\n",
    "dfor_v17['not_singletons'] = (~dfor_v17.family1.isin(singletop_fam1)) & (~dfor_v17.family2.isin(singletop_fam2))\n",
    "print(sum(dfor_v17.csi.isna() == False))\n",
    "print(sum(dfor_v17.not_singletons == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e5c2009",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfor_v16['alt_subset'] = dfor_v16.identifier != 'BZX-MLI-FFM-MLI'\n",
    "dfor_v16_25['alt_subset'] = dfor_v16_25.identifier != 'BZX-MLI-FFM-MLI'\n",
    "dfor_v16_100['alt_subset'] = dfor_v16_100.identifier != 'BZX-MLI-FFM-MLI'\n",
    "dfor_v17['alt_subset'] = dfor_v17.identifier != 'BZX-MLI-FFM-MLI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3f67748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The border 'XMW-MDG-PLT-MDG' is in buffers 25 and 100 but not in 50 so lets remove it from the 25 and 100\n",
    "dfor_v16_25 = dfor_v16_25[dfor_v16_25.identifier != 'XMW-MDG-PLT-MDG']\n",
    "dfor_v16_100 = dfor_v16_100[dfor_v16_100.identifier != 'XMW-MDG-PLT-MDG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9ef6a72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the variables used in the analysis and order them with the csi variables 1st\n",
    "var_to_keep = dfor.columns.tolist()\n",
    "var_to_keep.remove(\"csi\")\n",
    "var_to_keep.remove(\"csi_sd\")\n",
    "var_to_keep.remove(\"csi_change\")\n",
    "var_to_keep.remove(\"csi_change_sd\")\n",
    "\n",
    "var_to_keep = ['csi','csi_sd','csi_change','csi_change_sd','csi_oj','csi_change_oj','csi_sd_oj','csi_change_sd_oj','csi_alt','csi_change_alt',\n",
    "               'same_lang','not_singletons','alt_subset'] \\\n",
    "              + var_to_keep\n",
    "var_to_keep_enhanced = var_to_keep + crop_vars + crop_alt_vars\n",
    "\n",
    "dfor_v16[var_to_keep_enhanced].to_stata(pathdata + 'Dickens_rep_v16_50.dta', version=117)\n",
    "dfor_v16_25[var_to_keep].to_stata(pathdata + 'Dickens_rep_v16_25.dta', version=117)\n",
    "dfor_v16_100[var_to_keep].to_stata(pathdata + 'Dickens_rep_v16_100.dta', version=117)\n",
    "dfor_v17[var_to_keep].to_stata(pathdata + 'Dickens_rep_v17.dta', version=117)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26ac83a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_to_keep = dfor.columns.tolist()\n",
    "var_to_keep.remove(\"csi\")\n",
    "var_to_keep.remove(\"csi_sd\")\n",
    "var_to_keep.remove(\"csi_change\")\n",
    "var_to_keep.remove(\"csi_change_sd\")\n",
    "\n",
    "var_to_keep = ['csi','csi_sd','csi_change','csi_change_sd','csi_oj','csi_change_oj','csi_sd_oj','csi_change_sd_oj','same_lang','not_singletons'] + var_to_keep\n",
    "dfor_v16_all[var_to_keep].to_stata(pathdata + 'Dickens_rep_v16_50_allpairs.dta', version=117)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10eef09",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5381b71c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
